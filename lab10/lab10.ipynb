{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright **`(c)`** 2023 Giovanni Squillero `<giovanni.squillero@polito.it>`  \n",
    "[`https://github.com/squillero/computational-intelligence`](https://github.com/squillero/computational-intelligence)  \n",
    "Free for personal or classroom use; see [`LICENSE.md`](https://github.com/squillero/computational-intelligence/blob/master/LICENSE.md) for details.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB10\n",
    "\n",
    "Use reinforcement learning to devise a tic-tac-toe player.\n",
    "\n",
    "### Deadlines:\n",
    "\n",
    "* Submission: [Dies Natalis Solis Invicti](https://en.wikipedia.org/wiki/Sol_Invictus)\n",
    "* Reviews: [Befana](https://en.wikipedia.org/wiki/Befana)\n",
    "\n",
    "Notes:\n",
    "\n",
    "* Reviews will be assigned  on Monday, December 4\n",
    "* You need to commit in order to be selected as a reviewer (ie. better to commit an empty work than not to commit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "from collections import namedtuple, defaultdict\n",
    "from random import choice\n",
    "from copy import deepcopy\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "State = namedtuple(\"State\", [\"x\", \"o\"])\n",
    "StateMove = namedtuple(\"StaeMove\", [\"state\", \"move\"])\n",
    "MAGIC = [2, 7, 6, 9, 5, 1, 4, 3, 8]\n",
    "WINNING_REWARD = 10\n",
    "LOSING_REWARD = -1\n",
    "GAME_PLAYED = 1000\n",
    "EPSILON = 0.001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def win(elements):\n",
    "    \"\"\"Checks is elements is winning\"\"\"\n",
    "    return any(sum(c) == 15 for c in combinations(elements, 3))\n",
    "\n",
    "\n",
    "def state_value(pos: State):\n",
    "    \"\"\"Evaluate state: +1 first player wins\"\"\"\n",
    "    if win(pos.x):\n",
    "        return WINNING_REWARD\n",
    "    elif win(pos.o):\n",
    "        return LOSING_REWARD\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def clever_player(state: State, player=1):\n",
    "    \"\"\"checks if he has a winnig move and if the opponent has a winng move player \n",
    "    if player=0 plays the first move of every turn\"\"\"\n",
    "    if player == 1:\n",
    "        state = deepcopy(state)\n",
    "        available = set(range(1, 9 + 1)) - state.x - state.o  # create a set with the all possible moves\n",
    "        for c in combinations(state.o, 2):\n",
    "            if 15 - sum(c) in available:\n",
    "                state.o.add(15 - sum(c))\n",
    "                return state\n",
    "        for c in combinations(state.x, 2):\n",
    "            if 15 - sum(c) in available:\n",
    "                state.o.add(15 - sum(c))\n",
    "                return state\n",
    "        rand = choice(list(available))\n",
    "        state.o.add(rand)\n",
    "        return state\n",
    "    else:\n",
    "        state = deepcopy(state)\n",
    "        available = set(range(1, 9 + 1)) - state.x - state.o  # create a set with the all possible moves\n",
    "        for c in combinations(state.x, 2):\n",
    "            if 15 - sum(c) in available:\n",
    "                state.x.add(15 - sum(c))\n",
    "                return state\n",
    "        for c in combinations(state.o, 2):\n",
    "            if 15 - sum(c) in available:\n",
    "                state.x.add(15 - sum(c))\n",
    "                return state\n",
    "        rand = choice(list(available))\n",
    "        state.x.add(rand)\n",
    "        return state\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clever_game():\n",
    "    \"\"\"play a game using the clever strategy\"\"\"\n",
    "    trajectory = list()\n",
    "    state = State(set(), set())\n",
    "    available = set(range(1, 9 + 1))\n",
    "    while available:\n",
    "        new_state = clever_player(deepcopy(state), player=0)\n",
    "        x = new_state.x - state.x\n",
    "        x = x.pop()\n",
    "        trajectory.append(StateMove(deepcopy(state), x))\n",
    "        state.x.add(x)\n",
    "        available.remove(x)\n",
    "        if win(state.x) or not available:\n",
    "            trajectory.append(StateMove(deepcopy(state), 100))#100 to signal that there is no move\n",
    "            break\n",
    "        new_state = clever_player(deepcopy(state), player=1)\n",
    "        o = new_state.o - state.o\n",
    "        o = o.pop()\n",
    "        state.o.add(o)\n",
    "        available.remove(o)\n",
    "        if win(state.o):\n",
    "            break\n",
    "    return trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_game(player=0):\n",
    "    \"\"\"play a game with legal and random move\"\"\"\n",
    "    trajectory = list()\n",
    "    state = State(set(), set())\n",
    "    available = set(range(1, 9 + 1))\n",
    "    while available:\n",
    "        x = choice(list(available))\n",
    "        if player == 0:\n",
    "            trajectory.append(StateMove(deepcopy(state), x))\n",
    "        state.x.add(x)\n",
    "        available.remove(x)\n",
    "        if win(state.x) or not available:\n",
    "            if player == 0:\n",
    "                trajectory.append(StateMove(deepcopy(state), x))\n",
    "            break\n",
    "        o = choice(list(available))\n",
    "        if player == 1:\n",
    "            trajectory.append(StateMove(deepcopy(state), x))\n",
    "        state.o.add(o)\n",
    "        available.remove(o)\n",
    "        if win(state.o):\n",
    "            break\n",
    "    return trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 280/500000 [00:00<11:03, 753.32it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500000/500000 [07:10<00:00, 1162.48it/s]\n"
     ]
    }
   ],
   "source": [
    "value_dictionary = defaultdict(float)\n",
    "\n",
    "# add a new hashmap considering the acual state and the next state of the trajectory\n",
    "for steps in tqdm(range(500_000)):\n",
    "    trajectory = clever_game()\n",
    "    final_reward = state_value(trajectory[-1].state)\n",
    "    for state_move in trajectory:\n",
    "        hashable_state = (frozenset(state_move.state.x), frozenset(state_move.state.o), state_move.move)\n",
    "        value_dictionary[hashable_state] = value_dictionary[hashable_state] + EPSILON * (\n",
    "            final_reward - value_dictionary[hashable_state]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def montcarlo_player(state: State):\n",
    "    \"\"\"this function chooses based on the dict build before during learning \"\"\"\n",
    "    state = deepcopy(state)\n",
    "    optimal_value = -float('inf')  # smallest float in python\n",
    "    optimal_move = 10  # just initializing the variable\n",
    "    avaibles = set(range(1, 9 + 1)) - state.x - state.o\n",
    "    for option in avaibles:\n",
    "        hashable_state = (frozenset(state.x), frozenset(state.o), option)\n",
    "        if value_dictionary[hashable_state] > optimal_value:\n",
    "            optimal_value = value_dictionary[hashable_state]\n",
    "            optimal_move = option\n",
    "    state.x.add(optimal_move)\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wins=869 losses=119\n"
     ]
    }
   ],
   "source": [
    "wins = 0\n",
    "losses = 0\n",
    "for _ in range(GAME_PLAYED):\n",
    "    state = State(set(), set())\n",
    "    while 1:\n",
    "        state = montcarlo_player(state)\n",
    "        if state_value(state) == WINNING_REWARD:\n",
    "            wins += 1\n",
    "            break\n",
    "        if len(state.x) + len(state.o) == 9:\n",
    "            break\n",
    "        state = clever_player(state)\n",
    "        if state_value(state) == LOSING_REWARD:\n",
    "            losses += 1\n",
    "            break\n",
    "print(f\"wins={wins} losses={losses}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ci-fLJ3OwGs-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
